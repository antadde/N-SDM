% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nsdm.evaluate3.R
\name{nsdm.evaluate3}
\alias{nsdm.evaluate3}
\title{nsdm.evaluate3}
\usage{
nsdm.evaluate3(
  x,
  tester = data.frame(),
  thres = numeric(),
  crit = "pp=op",
  prevalence_correction = FALSE,
  level,
  ncores = ncores,
  tmp_path = NULL
)
}
\arguments{
\item{x}{A nsdm.fit object}

\item{tester}{Data.frame with testing data (only mandatory if replicatetype='none' was chosen when models were fitted)}

\item{thres}{A character vector of the same length as number of models chosen with custom thresholds for model evaluation. for nsdm.flex outputs the thresholds have to be labelled with the same names provided to models}

\item{crit}{A character string indicating which threshold criterion should be considered? Currently 'pp=op'(predicted prevalence = observed prevalence), 'maxTSS' (threshold yielding maximum TSS), and 'external' (thresholds manually supplied) are possible}

\item{prevalence_correction}{Logical (TRUE FALSE) should imbalanced presence/absence data be upsampled to prevalence 0.5 for model evaluation.}

\item{level}{A character string indicating the evaluated level (e.g. CH or EU)}

\item{ncores}{Number of cores to be used during parallel operations}

\item{tmp_path}{A character string indicating the path where to store gbm temporary outputs}
}
\value{
An object of class 'nsdm.evaluation'
}
\description{
Parallel evaluation of nsdm.fit models with a suite of model assessment metrics (parallel version)
}
\author{
Philipp Brun (philipp.brun@wsl.ch) and Antoine Adde (aadde@unil.ch)
}
