#' nsdm.bigextract
#'
#' Parallelized loading and spatiotemporal extraction of large raster datasets.
#'
#' @param cov A character vector specifying the file paths of individual raster layers.
#' @param data An `nsdm.pseudoabsences` object used for covariate extraction.
#' @param rst_ref A raster object used as a reference (for cell identifiers, CRS, extent, etc.).
#' @param cov_info A `data.frame` containing key covariate information, as generated by `nsdm.covinfo`.
#' @param t_match Logical; whether to perform temporal matching (`TRUE`) or not (`FALSE`).
#' @param tmatch_scheme A character string specifying the temporal matching scheme:  
#'   - `"npts"`: nearest previous time  
#'   - `"nts"`: nearest time
#' @param nzvt A numeric threshold specifying the minimum number of unique values required for a covariate to be retained in the candidate set.
#' @param nsplits An integer indicating the number of cores to use for parallel extraction.
#'
#' @return An updated `nsdm.pseudoabsences` object.
#' @author Antoine Adde (antoine.adde@eawag.ch)
#' @export

nsdm.bigextract<-function(cov, data, rst_ref, cov_info, t_match=FALSE, tmatch_scheme="npts", nzvt=10, nsplits=ncores){

 # Get data
xy <- data@xy
pa <- data@pa
years <- data@years
sid <- data@sid

# Isolate fst and tif covariates
cov_tif <- cov[grep("\\.tif$", cov)]  # should only be mainGLO
cov_fst <- cov[grep("\\.fst$", cov)]

### ------------------------
### Arrange layers for temporal matching or not
### ------------------------

# Retrieve cov-info table
cov_info_fst <- data.frame(cov_info[match(gsub("\\.fst$", "", basename(cov_fst)), 
                                          gsub("\\.tif$", "", basename(cov_info$file))), ])

### ------------------------
### Extract presences
### ------------------------

threads_fst(nr_of_threads = 1)

# Identify cell positions once
cells <- cellFromXY(rst_ref, xy[pa == 1, ])

# Extract values
suppressMessages({
  xt_pres <- mclapply(cov_fst, function(i) {
    if (file.exists(i)) {
      r <- read_fst(i)
      xt <- data.frame(r[cells, 1])
      names(xt) <- sub("\\.[^.]+$", "", basename(i))
      return(xt)
    } else {
      warning(paste("File not found:", i))
      return(NULL)
    }
  }, mc.cores = ncores)
})

# Check and combine safely
bad <- which(sapply(xt_pres, function(x) is.null(x) || !is.data.frame(x)))
if (length(bad) > 0) {
  bad_names <- names(xt_pres)[bad]
  stop("Invalid elements in xt_pres:\n",
       paste0("  [", bad, "] ", bad_names, collapse = "\n"))
}

nrows <- sapply(xt_pres, nrow)
if (length(unique(nrows)) > 1) {
  row_info <- paste0("[", seq_along(nrows), "] ", names(xt_pres), ": ", nrows)
  stop("Row mismatch across xt_pres elements:\n", paste(row_info, collapse = "\n"))
}

xt_pres <- do.call(cbind, xt_pres)

# Only run temporal matching if years are available and t_match is TRUE and temporal covariates are available
cov_info_fst_tempo <- cov_info_fst[!is.na(cov_info_fst$year), ]
if (!all(is.na(years)) && isTRUE(t_match) && nrow(cov_info_fst_tempo) > 0) {

  # Get years corresponding to PA == 1
  y_sp <- years[pa == 1]

  # Filter and prepare temporal covariate information
  cov_info_fst_tempo <- unique(cov_info_fst_tempo[, c("dataset", "year")])
  cov_info_fst_tempo_split_list <- split(cov_info_fst_tempo, cov_info_fst_tempo$dataset)

  xt_pres_dup <- vector("list", length = nrow(xt_pres))

  for (r in seq_len(nrow(xt_pres))) {
    y_r <- y_sp[r]
    xt_pres_sta_r <- xt_pres[r, ]

    to_remove <- unlist(lapply(cov_info_fst_tempo_split_list, function(x) {
      if (nrow(x) == 0) return(character(0))

      if (tmatch_scheme == "npts") {
        
		# Strategy: Nearest previous time only
        past_years <- x$year[x$year < y_r]

		if (length(past_years) == 0) {
		  # No previous year: assign the nearest year overall
		  prev_year <- x$year[which.min(abs(x$year - y_r))]
		} else {
		  # There are past years: pick the closest past one
		  prev_year <- max(past_years)
		}

       to_remove_years <- x$year[x$year != prev_year]

      } else if (tmatch_scheme == "nts") {
        # Strategy: Nearest overall (previous or future)
        closest_idx <- which.min(abs(x$year - y_r))
        to_remove_years <- x$year[-closest_idx]

      } else {
        stop("Unknown tmatch_scheme: use 'npts' or 'nts'")
      }

      paste(x$dataset[x$year %in% to_remove_years], to_remove_years, sep = "_")
    }))

    # Remove columns not matching the selected temporal layer
    pattern <- paste(to_remove, collapse = "|")
    matching_indices <- grep(pattern, names(xt_pres_sta_r))
    xt_pres_sta_r <- xt_pres_sta_r[, -matching_indices, drop = FALSE]

    # Remove year info from column names
    names(xt_pres_sta_r) <- gsub("_[0-9]+_", "_TBD_", names(xt_pres_sta_r))

    xt_pres_dup[[r]] <- xt_pres_sta_r
  }

  # Combine into final matrix
  xt_pres <- do.call(rbind, xt_pres_dup)
  
 # Flatten max years as named vector
mx_y <- unlist(lapply(cov_info_fst_tempo_split_list, function(x) max(x$year)))

# Get current names
nm <- names(xt_pres)

# Replace 'TBD' with the max year based on dataset in each name
for (dataset in names(mx_y)) {
  pattern <- paste0("(", dataset, ")_TBD")
  replacement <- paste0("\\1_", mx_y[dataset])
  nm <- gsub(pattern, replacement, nm)
}

# Apply new names
names(xt_pres) <- nm 
}

### ------------------------
### Extract absences
### ------------------------
# Get the basenames (without extension) of all .fst files
fst_basenames <- sub("\\.[^.]+$", "", basename(cov_fst))

# Get the names of xt_pres_sta
xt_names <- names(xt_pres)

# Match and retrieve paths
matched_cov_fst <- cov_fst[fst_basenames %in% xt_names]

# Identify cell positions for absence points
cells <- cellFromXY(rst_ref, xy[pa == 0,])

  suppressMessages(xt_abs <- mclapply(matched_cov_fst, function(i) {
    if (file.exists(i)) {
      r <- read_fst(i)
      xt <- data.frame(r[cells, 1])
      names(xt) <- sub("\\.[^.]+$", "", basename(i))
      return(xt)
    } else {
      warning(paste("File not found:", i))
      return(NULL)
    }
  }, mc.cores = ncores))
  
  # Remove any NULL results before binding
  xt_abs <- xt_abs[!sapply(xt_abs, is.null)]
  
  # Finalize
   xt_abs <- do.call(cbind, xt_abs)


### ------------------------
### Combine and clean
### ------------------------

# Initialize a list to track filtered-out layers
filtered_out_layers <- list(unique_values = NULL, near_zero_variance = NULL)

# Combine presence and absence data
 env_vars <- rbind(xt_pres, xt_abs)

# Proceed only if env_vars is not empty
if (!is.null(env_vars) && ncol(env_vars) > 0) {

  # Clean for columns with unique values where p == 1
  lenv <- apply(env_vars[which(pa == 1), , drop = FALSE], 2, function(x) length(unique(x)))
  unique_cols <- which(lenv == 1)

  if (length(unique_cols) > 0) {
    filtered_out_layers$unique_values <- colnames(env_vars)[unique_cols]  # Store removed layers
    if (ncol(env_vars) > length(unique_cols)) {
      env_vars <- env_vars[, -unique_cols, drop = FALSE]
    } else {
      warning("All columns were removed due to unique values in p == 1 subset.")
      env_vars <- NULL
    }
  }

  # Clean for near-zero variance columns
  if (is.numeric(nzvt)) {
    nzv_cols <- which(apply(env_vars, 2, function(x) length(unique(x))) < nzvt)
    if (length(nzv_cols) > 0) {
      filtered_out_layers$near_zero_variance <- colnames(env_vars)[nzv_cols]  # Store removed layers
      if (ncol(env_vars) > length(nzv_cols)) {
        env_vars <- env_vars[, -nzv_cols, drop = FALSE]
      } else {
        warning("All columns were removed due to near-zero variance filtering.")
        env_vars <- NULL
      }
    }
  }
  
} else {
  warning("env_vars is NULL or empty after combining presences and absences.")
}

# Identify unmatched layers from cov_info
filtered_out_layers$unmatched_covariates <- setdiff(
  gsub("\\.tif$", "", basename(cov_info$file)),
  colnames(env_vars)  # Existing covariate names
)

### ------------------------
### Extract mainGLO
### ------------------------

if (!is.null(cov_tif) && length(cov_tif) > 0) {
  
  # Ensure `xy` is valid before extracting cells
  if (!is.null(xy) && nrow(xy) > 0) {
    
    # Identify cells
    cells <- cellFromXY(rst_ref, xy)

    # Ensure all raster files exist before loading
    if (all(file.exists(cov_tif))) {
      
      # Load raster stack
      l <- rast(cov_tif)
      
      # extract
      xt_glo <- data.frame(extract(l, xy))

      # Ensure column names are correctly assigned
      colnames(xt_glo) <- names(l)

      # Combine with `env_vars`, ensuring `env_vars` is not NULL
      if (!is.null(env_vars) && ncol(env_vars) > 0) {
        env_vars <- cbind(env_vars, xt_glo)
      } else {
        env_vars <- xt_glo  # Initialize `env_vars` if it was NULL
      }

    } else {
      warning("Some files in `cov_tif` do not exist. Skipping mainGLO extraction.")
    }
    
  } else {
    warning("`xy` is NULL or empty, skipping `cellFromXY()` step.")
  }
  
}

### ------------------------
### Update and return
### ------------------------

# Identify rows with NA values
na_ix <- which(!complete.cases(env_vars))

# Remove rows with NAs if any exist
if (length(na_ix) > 0) {
  env_vars <- env_vars[-na_ix, , drop = FALSE]
  xy <- xy[-na_ix, , drop = FALSE]
  pa <- pa[-na_ix]
  years <- years[-na_ix]
  sid <- sid[-na_ix]
}

# Check if `data` is an S4 object and contains required slots
  # Update `data` object
  data@env_vars <- env_vars
  data@xy <- xy
  data@pa <- pa
  data@years <- years
  data@sid <- sid

return(list(data = data, filtered_out_layers = filtered_out_layers))
}
